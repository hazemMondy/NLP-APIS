{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sentence_transformers.util import cos_sim\n",
    "import sys\n",
    "import key_words\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pickle\n",
    "def save_obj(obj:object,name:str):\n",
    "    ext = '.pickle'\n",
    "    with open(name + ext, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name:str)->object:\n",
    "    ext = '.pickle'\n",
    "    with open(name + ext, 'rb') as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train_phase1.tsv\"\n",
    "df = pd.read_csv(train_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_answers = load_obj('data/essaySet_3_model_answers')\n",
    "docs = df.query(f'EssaySet == {3}')[\"EssayText\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enclosure_hard = \"\\\"\\\"\"\n",
    "enclosure_soft = \"\\\"\\\"@@\"\n",
    "enclosure_mediam = \"\\\"\\\"@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hazem is playing \"\"@football@\"\" in the \"\"@@stadium@@\"\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = \"hazem is playing \\\"\\\"@football@\\\"\\\" in the \\\"\\\"@@stadium@@\\\"\\\"\"\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@@stadium@@'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(['@football@', '@@stadium@@'])-set(['@football@'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_keywords_soft = key_words.get_str_between(answer, enclosure_soft)\n",
    "manual_keywords_mediam = key_words.get_str_between(answer, enclosure_mediam)\n",
    "manual_keywords_hard = key_words.get_str_between(answer, enclosure_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['stadium'], ['football', '@stadium@'], ['@football@', '@@stadium@@'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_keywords_soft, manual_keywords_mediam, manual_keywords_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in manual_keywords_mediam:\n",
    "    answer = answer.replace(enclosure_mediam+str(i)+enclosure_mediam[::-1], '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hazem is playing  in the '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(n_grams, doc):\n",
    "    x = list(map(lambda gram :\n",
    "        key_words.candidates_tokens(str(doc), n_gram_range=gram)\n",
    "        , n_grams))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(ls_ls):\n",
    "    out = []\n",
    "    for ls in ls_ls:\n",
    "        if isinstance(ls, list):\n",
    "            out.extend(ls)\n",
    "        else:\n",
    "            out.append(ls)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(manual_keywords_soft) - set(manual_keywords_mediam)\n",
    "ngrams = [*set(list(map(lambda x : len(x.split(' ')),  list(words))))]\n",
    "ngram = max(ngrams), min(ngrams)\n",
    "docs_candidates = list(map(lambda doc : get_candidates([ngram], doc), docs))\n",
    "# flatten\n",
    "docs_candidates = list(map(flatten , docs_candidates))\n",
    "docs_candidates_emb = list(map(model.encode, docs_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oeb\\AppData\\Local\\Temp/ipykernel_2248/951429711.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array(docs_candidates_emb).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1891,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(docs_candidates_emb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_threshold = 0.75\n",
    "mediam_threshold = 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(map(lambda docs_cand :cos_sim(model.encode(manual_keywords_soft), docs_cand).__array__().max(axis=1) > soft_threshold, docs_candidates_emb))).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda docs_cand :cos_sim(model.encode(manual_keywords_mediam), docs_cand).__array__().max(axis=1) > mediam_threshold, docs_candidates_emb[:10]))).astype(float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f876b07db73824ba94c3da26a300833b9286c0dd0d4e31723ae4574ddd9b9bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
